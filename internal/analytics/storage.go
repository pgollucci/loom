package analytics

import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"time"
)

// rebindQuery converts ? placeholders to $1, $2, ... for PostgreSQL.
func rebindQuery(query string) string {
	n := 0
	out := make([]byte, 0, len(query)+16)
	for i := 0; i < len(query); i++ {
		if query[i] == '?' {
			n++
			out = append(out, []byte(fmt.Sprintf("$%d", n))...)
		} else {
			out = append(out, query[i])
		}
	}
	return string(out)
}

// DatabaseStorage implements Storage using PostgreSQL
type DatabaseStorage struct {
	db *sql.DB
}

// NewDatabaseStorage creates a new database-backed storage
func NewDatabaseStorage(db *sql.DB) (*DatabaseStorage, error) {
	storage := &DatabaseStorage{db: db}
	if err := storage.initSchema(); err != nil {
		return nil, err
	}
	return storage, nil
}

// initSchema creates the analytics_request_logs table
func (s *DatabaseStorage) initSchema() error {
	schema := `
	CREATE TABLE IF NOT EXISTS analytics_request_logs (
		id TEXT PRIMARY KEY,
		timestamp TIMESTAMP NOT NULL,
		user_id TEXT NOT NULL,
		method TEXT NOT NULL,
		path TEXT NOT NULL,
		provider_id TEXT,
		model_name TEXT,
		prompt_tokens INTEGER,
		completion_tokens INTEGER,
		total_tokens INTEGER,
		latency_ms INTEGER,
		status_code INTEGER,
		cost_usd REAL,
		error_message TEXT,
		request_body TEXT,
		response_body TEXT,
		metadata_json TEXT,
		created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
	);

	CREATE INDEX IF NOT EXISTS idx_analytics_request_logs_timestamp ON analytics_request_logs(timestamp);
	CREATE INDEX IF NOT EXISTS idx_analytics_request_logs_user_id ON analytics_request_logs(user_id);
	CREATE INDEX IF NOT EXISTS idx_analytics_request_logs_provider_id ON analytics_request_logs(provider_id);
	CREATE INDEX IF NOT EXISTS idx_analytics_request_logs_created_at ON analytics_request_logs(created_at);
	`

	_, err := s.db.Exec(schema)
	return err
}

// SaveLog persists a request log
func (s *DatabaseStorage) SaveLog(ctx context.Context, log *RequestLog) error {
	metadataJSON, err := json.Marshal(log.Metadata)
	if err != nil {
		metadataJSON = []byte("{}")
	}

	query := rebindQuery(`
		INSERT INTO analytics_request_logs (
			id, timestamp, user_id, method, path, provider_id, model_name,
			prompt_tokens, completion_tokens, total_tokens, latency_ms,
			status_code, cost_usd, error_message, request_body, response_body,
			metadata_json
		) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
	`)

	_, err = s.db.ExecContext(ctx, query,
		log.ID,
		log.Timestamp,
		log.UserID,
		log.Method,
		log.Path,
		log.ProviderID,
		log.ModelName,
		log.PromptTokens,
		log.CompletionTokens,
		log.TotalTokens,
		log.LatencyMs,
		log.StatusCode,
		log.CostUSD,
		log.ErrorMessage,
		log.RequestBody,
		log.ResponseBody,
		string(metadataJSON),
	)

	return err
}

// GetLogs retrieves logs with filtering
func (s *DatabaseStorage) GetLogs(ctx context.Context, filter *LogFilter) ([]*RequestLog, error) {
	query := `
		SELECT 
			id, timestamp, user_id, method, path, provider_id, model_name,
			prompt_tokens, completion_tokens, total_tokens, latency_ms,
			status_code, cost_usd, error_message, request_body, response_body,
			metadata_json
		FROM analytics_request_logs
		WHERE 1=1
	`
	args := []interface{}{}

	if filter.UserID != "" {
		query += " AND user_id = ?"
		args = append(args, filter.UserID)
	}

	if filter.ProviderID != "" {
		query += " AND provider_id = ?"
		args = append(args, filter.ProviderID)
	}

	if !filter.StartTime.IsZero() {
		query += " AND timestamp >= ?"
		args = append(args, filter.StartTime)
	}

	if !filter.EndTime.IsZero() {
		query += " AND timestamp <= ?"
		args = append(args, filter.EndTime)
	}

	query += " ORDER BY timestamp DESC"

	if filter.Limit > 0 {
		query += " LIMIT ?"
		args = append(args, filter.Limit)
		if filter.Offset > 0 {
			query += " OFFSET ?"
			args = append(args, filter.Offset)
		}
	}

	rows, err := s.db.QueryContext(ctx, rebindQuery(query), args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var logs []*RequestLog
	for rows.Next() {
		log := &RequestLog{}
		var metadataJSON string

		err := rows.Scan(
			&log.ID,
			&log.Timestamp,
			&log.UserID,
			&log.Method,
			&log.Path,
			&log.ProviderID,
			&log.ModelName,
			&log.PromptTokens,
			&log.CompletionTokens,
			&log.TotalTokens,
			&log.LatencyMs,
			&log.StatusCode,
			&log.CostUSD,
			&log.ErrorMessage,
			&log.RequestBody,
			&log.ResponseBody,
			&metadataJSON,
		)
		if err != nil {
			return nil, err
		}

		if metadataJSON != "" {
			if err := json.Unmarshal([]byte(metadataJSON), &log.Metadata); err != nil {
				// Log unmarshal error but continue
				log.Metadata = nil
			}
		}

		logs = append(logs, log)
	}

	return logs, rows.Err()
}

// GetLogStats computes aggregate statistics
func (s *DatabaseStorage) GetLogStats(ctx context.Context, filter *LogFilter) (*LogStats, error) {
	baseQuery := `
		SELECT 
			COUNT(*) as total_requests,
			COALESCE(SUM(total_tokens), 0) as total_tokens,
			COALESCE(SUM(cost_usd), 0) as total_cost,
			COALESCE(AVG(latency_ms), 0) as avg_latency,
			COALESCE(SUM(CASE WHEN status_code >= 400 THEN 1 ELSE 0 END), 0) as error_count
		FROM analytics_request_logs
		WHERE 1=1
	`
	args := []interface{}{}

	if filter.UserID != "" {
		baseQuery += " AND user_id = ?"
		args = append(args, filter.UserID)
	}

	if filter.ProviderID != "" {
		baseQuery += " AND provider_id = ?"
		args = append(args, filter.ProviderID)
	}

	if !filter.StartTime.IsZero() {
		baseQuery += " AND timestamp >= ?"
		args = append(args, filter.StartTime)
	}

	if !filter.EndTime.IsZero() {
		baseQuery += " AND timestamp <= ?"
		args = append(args, filter.EndTime)
	}

	stats := &LogStats{
		RequestsByUser:     make(map[string]int64),
		RequestsByProvider: make(map[string]int64),
		CostByProvider:     make(map[string]float64),
		CostByUser:         make(map[string]float64),
		TokensByProvider:   make(map[string]int64),
		TokensByUser:       make(map[string]int64),
		LatencyByProvider:  make(map[string]float64),
	}

	var errorCount int64
	row := s.db.QueryRowContext(ctx, rebindQuery(baseQuery), args...)
	err := row.Scan(
		&stats.TotalRequests,
		&stats.TotalTokens,
		&stats.TotalCostUSD,
		&stats.AvgLatencyMs,
		&errorCount,
	)
	if err != nil {
		return nil, err
	}

	if stats.TotalRequests > 0 {
		stats.ErrorRate = float64(errorCount) / float64(stats.TotalRequests)
	}

	// Get per-user stats (requests, costs, tokens)
	userQuery := fmt.Sprintf(`
		SELECT user_id, COUNT(*) as count, COALESCE(SUM(cost_usd), 0) as cost,
		       COALESCE(SUM(total_tokens), 0) as tokens
		FROM analytics_request_logs
		WHERE 1=1 %s AND user_id IS NOT NULL AND user_id != ''
		GROUP BY user_id
	`, buildWhereClause(filter))

	rows, err := s.db.QueryContext(ctx, rebindQuery(userQuery), buildWhereArgs(filter)...)
	if err == nil {
		defer rows.Close()
		for rows.Next() {
			var userID string
			var count int64
			var cost float64
			var tokens int64
			if err := rows.Scan(&userID, &count, &cost, &tokens); err == nil {
				stats.RequestsByUser[userID] = count
				stats.CostByUser[userID] = cost
				stats.TokensByUser[userID] = tokens
			}
		}
	}

	// Get per-provider stats (requests, costs, tokens, latency)
	providerQuery := fmt.Sprintf(`
		SELECT provider_id, COUNT(*) as count, COALESCE(SUM(cost_usd), 0) as cost,
		       COALESCE(SUM(total_tokens), 0) as tokens, COALESCE(AVG(latency_ms), 0) as avg_latency
		FROM analytics_request_logs
		WHERE 1=1 %s AND provider_id IS NOT NULL AND provider_id != ''
		GROUP BY provider_id
	`, buildWhereClause(filter))

	rows, err = s.db.QueryContext(ctx, rebindQuery(providerQuery), buildWhereArgs(filter)...)
	if err == nil {
		defer rows.Close()
		for rows.Next() {
			var providerID string
			var count int64
			var cost float64
			var tokens int64
			var avgLatency float64
			if err := rows.Scan(&providerID, &count, &cost, &tokens, &avgLatency); err == nil {
				stats.RequestsByProvider[providerID] = count
				stats.CostByProvider[providerID] = cost
				stats.TokensByProvider[providerID] = tokens
				stats.LatencyByProvider[providerID] = avgLatency
			}
		}
	}

	return stats, nil
}

// DeleteOldLogs removes logs older than the specified time
func (s *DatabaseStorage) DeleteOldLogs(ctx context.Context, before time.Time) (int64, error) {
	result, err := s.db.ExecContext(ctx, rebindQuery("DELETE FROM analytics_request_logs WHERE timestamp < ?"), before)
	if err != nil {
		return 0, err
	}
	return result.RowsAffected()
}

// Helper functions for building queries
func buildWhereClause(filter *LogFilter) string {
	where := ""
	if filter.UserID != "" {
		where += " AND user_id = ?"
	}
	if filter.ProviderID != "" {
		where += " AND provider_id = ?"
	}
	if !filter.StartTime.IsZero() {
		where += " AND timestamp >= ?"
	}
	if !filter.EndTime.IsZero() {
		where += " AND timestamp <= ?"
	}
	return where
}

func buildWhereArgs(filter *LogFilter) []interface{} {
	args := []interface{}{}
	if filter.UserID != "" {
		args = append(args, filter.UserID)
	}
	if filter.ProviderID != "" {
		args = append(args, filter.ProviderID)
	}
	if !filter.StartTime.IsZero() {
		args = append(args, filter.StartTime)
	}
	if !filter.EndTime.IsZero() {
		args = append(args, filter.EndTime)
	}
	return args
}
