package worker

import (
	"context"
	"crypto/sha256"
	"encoding/hex"
	"errors"
	"fmt"
	"log"
	"strings"
	"sync"
	"time"

	"github.com/google/uuid"
	"github.com/jordanhubbard/loom/internal/actions"
	"github.com/jordanhubbard/loom/internal/database"
	"github.com/jordanhubbard/loom/internal/memory"
	"github.com/jordanhubbard/loom/internal/provider"
	"github.com/jordanhubbard/loom/pkg/models"
)

// Worker represents an agent worker that processes tasks
type Worker struct {
	id          string
	agent       *models.Agent
	provider    *provider.RegisteredProvider
	db          *database.Database
	textMode    bool // Use simple text-based actions instead of JSON
	status      WorkerStatus
	currentTask string
	startedAt   time.Time
	lastActive  time.Time
	ctx         context.Context
	cancel      context.CancelFunc
	mu          sync.RWMutex
}

// WorkerStatus represents the status of a worker
type WorkerStatus string

const (
	WorkerStatusIdle    WorkerStatus = "idle"
	WorkerStatusWorking WorkerStatus = "working"
	WorkerStatusStopped WorkerStatus = "stopped"
	WorkerStatusError   WorkerStatus = "error"
)

// NewWorker creates a new agent worker
func NewWorker(id string, agent *models.Agent, provider *provider.RegisteredProvider) *Worker {
	ctx, cancel := context.WithCancel(context.Background())

	return &Worker{
		id:         id,
		agent:      agent,
		provider:   provider,
		status:     WorkerStatusIdle,
		startedAt:  time.Now(),
		lastActive: time.Now(),
		ctx:        ctx,
		cancel:     cancel,
	}
}

// Start starts the worker
func (w *Worker) Start() error {
	w.mu.Lock()
	defer w.mu.Unlock()

	if w.status == WorkerStatusWorking {
		return fmt.Errorf("worker %s is already running", w.id)
	}

	w.status = WorkerStatusIdle
	w.lastActive = time.Now()

	log.Printf("Worker %s started for agent %s using provider %s", w.id, w.agent.Name, w.provider.Config.Name)

	// Worker is now ready to receive tasks
	// The actual task processing will be handled by the pool

	return nil
}

// Stop stops the worker
func (w *Worker) Stop() {
	w.mu.Lock()
	defer w.mu.Unlock()

	w.cancel()
	w.status = WorkerStatusStopped

	log.Printf("Worker %s stopped", w.id)
}

// SetDatabase sets the database for conversation context management
func (w *Worker) SetDatabase(db *database.Database) {
	w.mu.Lock()
	defer w.mu.Unlock()
	w.db = db
}

// ExecuteTask executes a task using the agent's persona and provider
// Supports multi-turn conversations when ConversationSession is provided or database is available
func (w *Worker) ExecuteTask(ctx context.Context, task *Task) (*TaskResult, error) {
	w.mu.Lock()
	if w.status != WorkerStatusIdle {
		w.mu.Unlock()
		return nil, fmt.Errorf("worker %s is not idle", w.id)
	}
	w.status = WorkerStatusWorking
	w.currentTask = task.ID
	w.lastActive = time.Now()
	w.mu.Unlock()

	defer func() {
		w.mu.Lock()
		w.status = WorkerStatusIdle
		w.currentTask = ""
		w.lastActive = time.Now()
		w.mu.Unlock()
	}()

	// Try to load or create conversation context
	var messages []provider.ChatMessage
	var conversationCtx *models.ConversationContext
	var err error

	if task.ConversationSession != nil {
		// Use provided conversation session
		conversationCtx = task.ConversationSession
	} else if w.db != nil && task.BeadID != "" && task.ProjectID != "" {
		// Try to load existing conversation from database
		conversationCtx, err = w.db.GetConversationContextByBeadID(task.BeadID)
		if err != nil {
			// No existing conversation, create new one
			log.Printf("No existing conversation for bead %s, creating new session", task.BeadID)
			conversationCtx = models.NewConversationContext(
				uuid.New().String(),
				task.BeadID,
				task.ProjectID,
				24*time.Hour, // Default 24h expiration
			)
			if w.agent != nil && w.agent.Name != "" {
				conversationCtx.Metadata["agent_name"] = w.agent.Name
			}

			// Save new session to database
			if err := w.db.CreateConversationContext(conversationCtx); err != nil {
				log.Printf("Warning: Failed to create conversation context: %v", err)
				conversationCtx = nil // Fall back to single-shot
			}
		} else if conversationCtx.IsExpired() {
			// Session expired, create new one
			log.Printf("Conversation session %s expired, creating new session", conversationCtx.SessionID)
			conversationCtx = models.NewConversationContext(
				uuid.New().String(),
				task.BeadID,
				task.ProjectID,
				24*time.Hour,
			)
			if w.agent != nil && w.agent.Name != "" {
				conversationCtx.Metadata["agent_name"] = w.agent.Name
			}

			if err := w.db.CreateConversationContext(conversationCtx); err != nil {
				log.Printf("Warning: Failed to create conversation context: %v", err)
				conversationCtx = nil
			}
		}
	}

	// Build message history
	if conversationCtx != nil {
		// Multi-turn conversation mode
		messages = w.buildConversationMessages(conversationCtx, task)

		// Handle token limits
		messages = w.handleTokenLimits(messages)
	} else {
		// Single-shot mode (backward compatibility)
		messages = w.buildSingleShotMessages(task)
	}

	// Create chat completion request
	req := &provider.ChatCompletionRequest{
		Model:          w.provider.Config.Model,
		Messages:       messages,
		Temperature:    0.1,
		ResponseFormat: w.responseFormat(),
	}

	// Send request to provider (with automatic context-length retry)
	resp, usedMessages, err := w.callWithContextRetry(ctx, req)
	if err != nil {
		return nil, fmt.Errorf("failed to get completion: %w", err)
	}

	// Extract result from response
	if len(resp.Choices) == 0 {
		return nil, fmt.Errorf("no response from provider")
	}

	// Store assistant response in conversation context
	if conversationCtx != nil && w.db != nil {
		// Convert provider messages back to conversation messages
		for _, msg := range usedMessages {
			// Only add new messages (not already in history)
			if len(conversationCtx.Messages) == 0 ||
				!w.messageExists(conversationCtx.Messages, msg.Content) {
				conversationCtx.AddMessage(msg.Role, msg.Content, len(msg.Content)/4)
			}
		}

		// Add assistant response
		conversationCtx.AddMessage(
			"assistant",
			resp.Choices[0].Message.Content,
			resp.Usage.CompletionTokens,
		)

		// Update conversation context in database
		if err := w.db.UpdateConversationContext(conversationCtx); err != nil {
			log.Printf("Warning: Failed to update conversation context: %v", err)
		}
	}

	result := &TaskResult{
		TaskID:      task.ID,
		WorkerID:    w.id,
		AgentID:     w.agent.ID,
		Response:    resp.Choices[0].Message.Content,
		TokensUsed:  resp.Usage.TotalTokens,
		CompletedAt: time.Now(),
		Success:     true,
	}

	return result, nil
}

// buildConversationMessages builds messages from conversation history + new task
func (w *Worker) buildConversationMessages(conversationCtx *models.ConversationContext, task *Task) []provider.ChatMessage {
	var messages []provider.ChatMessage

	// If no messages in history, add system prompt
	if len(conversationCtx.Messages) == 0 {
		systemPrompt := w.buildSystemPrompt()
		conversationCtx.AddMessage("system", systemPrompt, len(systemPrompt)/4)
	}

	// Convert conversation messages to provider messages
	for _, msg := range conversationCtx.Messages {
		messages = append(messages, provider.ChatMessage{
			Role:    msg.Role,
			Content: msg.Content,
		})
	}

	// Append new user message
	userPrompt := task.Description
	if task.Context != "" {
		userPrompt = fmt.Sprintf("%s\n\nContext:\n%s", userPrompt, task.Context)
	}

	messages = append(messages, provider.ChatMessage{
		Role:    "user",
		Content: userPrompt,
	})

	return messages
}

// buildSingleShotMessages builds messages for single-shot execution (no conversation history)
func (w *Worker) buildSingleShotMessages(task *Task) []provider.ChatMessage {
	systemPrompt := w.buildSystemPrompt()
	userPrompt := task.Description
	if task.Context != "" {
		userPrompt = fmt.Sprintf("%s\n\nContext:\n%s", userPrompt, task.Context)
	}

	return []provider.ChatMessage{
		{Role: "system", Content: systemPrompt},
		{Role: "user", Content: userPrompt},
	}
}

// handleTokenLimits truncates messages if they exceed model token limits
func (w *Worker) handleTokenLimits(messages []provider.ChatMessage) []provider.ChatMessage {
	// Get model token limit (default to 100K if not specified)
	modelLimit := w.getModelTokenLimit()
	maxTokens := int(float64(modelLimit) * 0.8) // Use 80% of limit

	// Calculate current tokens (rough estimate: 1 token ~= 4 characters)
	totalTokens := 0
	for _, msg := range messages {
		totalTokens += len(msg.Content) / 4
	}

	if totalTokens <= maxTokens {
		return messages // No truncation needed
	}

	// Strategy: Sliding window - keep system message + recent messages
	if len(messages) == 0 {
		return messages
	}

	systemMsg := messages[0] // Assume first message is system
	systemTokens := len(systemMsg.Content) / 4

	// Find how many recent messages we can keep
	recentTokens := 0
	startIndex := len(messages) // Start from end

	// Work backwards to find where to truncate
	for i := len(messages) - 1; i > 0; i-- {
		msgTokens := len(messages[i].Content) / 4
		if systemTokens+recentTokens+msgTokens > maxTokens {
			// Can't fit this message
			startIndex = i + 1
			break
		}
		recentTokens += msgTokens
	}

	// If we truncated messages, add notice
	if startIndex > 1 {
		truncatedCount := startIndex - 1 // Don't count system message
		noticeMsg := provider.ChatMessage{
			Role:    "system",
			Content: fmt.Sprintf("[Note: %d older messages truncated to stay within token limit]", truncatedCount),
		}

		// Build result: system message + notice + recent messages
		result := []provider.ChatMessage{systemMsg, noticeMsg}
		result = append(result, messages[startIndex:]...)
		return result
	}

	// No truncation needed (edge case)
	return messages
}

// getModelTokenLimit returns the token limit for the current model.
// Uses the provider's discovered context window (from heartbeat) if available,
// falling back to a conservative default.
func (w *Worker) getModelTokenLimit() int {
	if w.provider.Config.ContextWindow > 0 {
		return w.provider.Config.ContextWindow
	}
	// Conservative default if heartbeat hasn't discovered the context window yet
	return 32768
}

// truncateMessages drops older conversation messages to reduce token count.
// It always keeps the first message (system prompt) and the last message
// (current user request), dropping middle messages progressively.
// fraction is the portion of middle messages to keep (0.5 = keep half).
func truncateMessages(messages []provider.ChatMessage, fraction float64) []provider.ChatMessage {
	if len(messages) <= 2 {
		return messages
	}

	system := messages[0]
	last := messages[len(messages)-1]
	middle := messages[1 : len(messages)-1]

	keep := int(float64(len(middle)) * fraction)
	if keep < 0 {
		keep = 0
	}

	// Keep the most recent middle messages
	var result []provider.ChatMessage
	result = append(result, system)
	if keep > 0 {
		dropped := len(middle) - keep
		result = append(result, provider.ChatMessage{
			Role:    "system",
			Content: fmt.Sprintf("[Note: %d older messages dropped to fit context window]", dropped),
		})
		result = append(result, middle[len(middle)-keep:]...)
	} else {
		result = append(result, provider.ChatMessage{
			Role:    "system",
			Content: fmt.Sprintf("[Note: %d older messages dropped to fit context window]", len(middle)),
		})
	}
	result = append(result, last)
	return result
}

// callWithContextRetry calls CreateChatCompletion and retries with
// progressively smaller message windows on ContextLengthError.
// Returns the response and the final messages used (which may be truncated).
func (w *Worker) callWithContextRetry(ctx context.Context, req *provider.ChatCompletionRequest) (*provider.ChatCompletionResponse, []provider.ChatMessage, error) {
	// Attempt 1: use messages as-is
	resp, err := w.provider.Protocol.CreateChatCompletion(ctx, req)
	if err == nil {
		return resp, req.Messages, nil
	}

	var ctxErr *provider.ContextLengthError
	if !errors.As(err, &ctxErr) {
		return nil, req.Messages, err
	}

	// Retry with progressively smaller context windows.
	// Each attempt keeps a smaller fraction of the conversation history.
	fractions := []float64{0.5, 0.25, 0.0}
	messages := req.Messages

	for _, frac := range fractions {
		truncated := truncateMessages(messages, frac)
		log.Printf("[ContextRetry] Retrying with %.0f%% of history (%d -> %d messages)",
			frac*100, len(messages), len(truncated))

		retryReq := *req
		retryReq.Messages = truncated

		resp, err = w.provider.Protocol.CreateChatCompletion(ctx, &retryReq)
		if err == nil {
			return resp, truncated, nil
		}
		if !errors.As(err, &ctxErr) {
			return nil, truncated, err
		}
	}

	// Final fallback: we're at system+user only and still too big.
	// Truncate the user message content to half its size.
	minimal := truncateMessages(messages, 0.0)
	if len(minimal) >= 2 {
		last := &minimal[len(minimal)-1]
		if len(last.Content) > 2000 {
			half := len(last.Content) / 2
			last.Content = last.Content[:half] + "\n\n[Content truncated to fit context window]"
			log.Printf("[ContextRetry] Final attempt: truncated user message to %d chars", len(last.Content))

			retryReq := *req
			retryReq.Messages = minimal
			resp, err = w.provider.Protocol.CreateChatCompletion(ctx, &retryReq)
			if err == nil {
				return resp, minimal, nil
			}
		}
	}

	return nil, minimal, fmt.Errorf("context length exceeded after all retry attempts: %w", err)
}

// messageExists checks if a message with the same content already exists in history
func (w *Worker) messageExists(messages []models.ChatMessage, content string) bool {
	for _, msg := range messages {
		if msg.Content == content {
			return true
		}
	}
	return false
}

// buildSystemPrompt builds the system prompt: ReAct operating model first,
// brief persona role second.
func (w *Worker) buildSystemPrompt() string {
	// 1. Action format with ReAct pattern FIRST
	var prompt string
	if w.textMode {
		prompt = actions.SimpleJSONPrompt + "\n\n"
	} else {
		prompt = actions.ActionPrompt + "\n\n"
	}

	// 2. Brief persona role context
	persona := w.agent.Persona
	if persona == nil {
		prompt += fmt.Sprintf("# Your Role\nYou are %s. Act on the task given to you.\n\n", w.agent.Name)
	} else {
		prompt += "# Your Role\n"
		if persona.Character != "" {
			prompt += persona.Character + "\n"
		} else {
			prompt += fmt.Sprintf("You are %s.\n", w.agent.Name)
		}
		if persona.Mission != "" {
			prompt += "Mission: " + persona.Mission + "\n"
		}
		prompt += "\n"
	}

	return prompt
}

// responseFormat returns the ResponseFormat for LLM requests.
// Local vLLM servers support response_format: json_object for constrained
// decoding. Cloud/litellm proxies often choke on it, so we skip it when the
// provider endpoint is not a local address.
func (w *Worker) responseFormat() *provider.ResponseFormat {
	ep := w.provider.Config.Endpoint
	if strings.Contains(ep, "localhost") ||
		strings.Contains(ep, "127.0.0.1") ||
		strings.Contains(ep, ".local") ||
		strings.Contains(ep, ".local:") ||
		strings.HasPrefix(ep, "http://172.") || // Docker bridge gateway IPs
		strings.HasPrefix(ep, "http://10.") || // Private network ranges
		strings.HasPrefix(ep, "http://192.168.") {
		return &provider.ResponseFormat{Type: "json_object"}
	}
	// Cloud providers (NVIDIA NIM, OpenAI, Anthropic proxies) — don't force
	// json_object as it can conflict with litellm routing.
	return nil
}

// GetStatus returns the current worker status
func (w *Worker) GetStatus() WorkerStatus {
	w.mu.RLock()
	defer w.mu.RUnlock()
	return w.status
}

// GetInfo returns worker information
func (w *Worker) GetInfo() WorkerInfo {
	w.mu.RLock()
	defer w.mu.RUnlock()

	return WorkerInfo{
		ID:          w.id,
		AgentName:   w.agent.Name,
		PersonaName: w.agent.PersonaName,
		ProviderID:  w.provider.Config.ID,
		Status:      w.status,
		CurrentTask: w.currentTask,
		StartedAt:   w.startedAt,
		LastActive:  w.lastActive,
	}
}

// Task represents a task for a worker to execute
type Task struct {
	ID                  string
	Description         string
	Context             string
	BeadID              string
	ProjectID           string
	ConversationSession *models.ConversationContext // Optional: enables multi-turn conversation
}

// TaskResult represents the result of task execution
type TaskResult struct {
	TaskID             string
	WorkerID           string
	AgentID            string
	Response           string
	Actions            []actions.Result
	TokensUsed         int
	CompletedAt        time.Time
	Success            bool
	Error              string
	LoopIterations     int    // Set when action loop is used
	LoopTerminalReason string // Set when action loop is used
}

// WorkerInfo contains information about a worker
type WorkerInfo struct {
	ID          string
	AgentName   string
	PersonaName string
	ProviderID  string
	Status      WorkerStatus
	CurrentTask string
	StartedAt   time.Time
	LastActive  time.Time
}

// --- Multi-turn action loop ---

// LessonsProvider supplies and records project-specific lessons.
type LessonsProvider interface {
	GetLessonsForPrompt(projectID string) string
	GetRelevantLessons(projectID, taskContext string, topK int) string
	RecordLesson(projectID, category, title, detail, beadID, agentID string) error
}

// LoopConfig configures the multi-turn action loop.
type LoopConfig struct {
	MaxIterations   int
	Router          *actions.Router
	ActionContext   actions.ActionContext
	LessonsProvider LessonsProvider
	DB              *database.Database
	TextMode        bool // Use simple text-based actions (~10 commands) instead of JSON (60+)
	// OnProgress is called after each successful iteration so the caller can
	// update heartbeat timestamps and prevent stuck-agent timeouts on long tasks.
	OnProgress func()
}

// LoopResult contains the result of a multi-turn action loop.
type LoopResult struct {
	*TaskResult
	Iterations     int                    `json:"iterations"`
	TerminalReason string                 `json:"terminal_reason"` // "completed", "max_iterations", "escalated", "error", "no_actions", "parse_failures", "progress_stagnant"
	ActionLog      []ActionLogEntry       `json:"action_log"`
	Metadata       map[string]interface{} `json:"metadata,omitempty"` // For progress metrics and remediation analysis
}

// ActionLogEntry records a single iteration of the action loop.
type ActionLogEntry struct {
	Iteration int              `json:"iteration"`
	Actions   []actions.Action `json:"actions"`
	Results   []actions.Result `json:"results"`
	Timestamp time.Time        `json:"timestamp"`
}

// isConversationalResponse detects when the model slips into chat mode
// instead of returning a JSON action.
func isConversationalResponse(response string) bool {
	lower := strings.ToLower(response)
	patterns := []string{
		"what would you like",
		"what do you want me to",
		"how would you like me to",
		"shall i",
		"would you like me to",
		"let me know if",
		"please let me know",
		"do you want me to",
		"what should i do next",
		"how should i proceed",
		"awaiting your instructions",
		"waiting for your input",
		"please provide",
		"could you clarify",
	}
	for _, p := range patterns {
		if strings.Contains(lower, p) {
			return true
		}
	}
	return false
}

// ExecuteTaskWithLoop runs the task in a multi-turn action loop:
// call LLM → parse actions → execute → format results → feed back → repeat.
func (w *Worker) ExecuteTaskWithLoop(ctx context.Context, task *Task, config *LoopConfig) (*LoopResult, error) {
	w.textMode = config.TextMode
	w.mu.Lock()
	if w.status != WorkerStatusIdle {
		w.mu.Unlock()
		return nil, fmt.Errorf("worker %s is not idle", w.id)
	}
	w.status = WorkerStatusWorking
	w.currentTask = task.ID
	w.lastActive = time.Now()
	w.mu.Unlock()

	defer func() {
		w.mu.Lock()
		w.status = WorkerStatusIdle
		w.currentTask = ""
		w.lastActive = time.Now()
		w.mu.Unlock()
	}()

	maxIter := config.MaxIterations
	if maxIter <= 0 {
		maxIter = 25
	}

	// Build initial messages
	var messages []provider.ChatMessage
	var conversationCtx *models.ConversationContext

	if task.ConversationSession != nil {
		conversationCtx = task.ConversationSession
	} else if config.DB != nil && task.BeadID != "" && task.ProjectID != "" {
		var err error
		conversationCtx, err = config.DB.GetConversationContextByBeadID(task.BeadID)
		if err != nil {
			conversationCtx = models.NewConversationContext(
				uuid.New().String(), task.BeadID, task.ProjectID, 24*time.Hour,
			)
			if w.agent != nil && w.agent.Name != "" {
				conversationCtx.Metadata["agent_name"] = w.agent.Name
			}
			if createErr := config.DB.CreateConversationContext(conversationCtx); createErr != nil {
				log.Printf("[ActionLoop] Warning: Failed to create conversation context: %v", createErr)
				conversationCtx = nil
			}
		} else if conversationCtx != nil && conversationCtx.IsExpired() {
			conversationCtx = models.NewConversationContext(
				uuid.New().String(), task.BeadID, task.ProjectID, 24*time.Hour,
			)
			if w.agent != nil && w.agent.Name != "" {
				conversationCtx.Metadata["agent_name"] = w.agent.Name
			}
			if createErr := config.DB.CreateConversationContext(conversationCtx); createErr != nil {
				conversationCtx = nil
			}
		}
	}

	// Build system prompt with lessons
	systemPrompt := w.buildEnhancedSystemPrompt(config.LessonsProvider, task.ProjectID, task.Context)

	if conversationCtx != nil {
		if len(conversationCtx.Messages) == 0 {
			conversationCtx.AddMessage("system", systemPrompt, len(systemPrompt)/4)
		}
		for _, msg := range conversationCtx.Messages {
			messages = append(messages, provider.ChatMessage{Role: msg.Role, Content: msg.Content})
		}
		userPrompt := task.Description
		if task.Context != "" {
			userPrompt = fmt.Sprintf("%s\n\nContext:\n%s", userPrompt, task.Context)
		}
		messages = append(messages, provider.ChatMessage{Role: "user", Content: userPrompt})
	} else {
		userPrompt := task.Description
		if task.Context != "" {
			userPrompt = fmt.Sprintf("%s\n\nContext:\n%s", userPrompt, task.Context)
		}
		messages = []provider.ChatMessage{
			{Role: "system", Content: systemPrompt},
			{Role: "user", Content: userPrompt},
		}
	}

	loopResult := &LoopResult{
		TaskResult: &TaskResult{
			TaskID:   task.ID,
			WorkerID: w.id,
			AgentID:  w.agent.ID,
			Success:  true,
		},
	}

	tracker := NewProgressTracker(maxIter)

	var allActions []actions.Result
	consecutiveParseFailures := 0
	consecutiveValidationFailures := 0
	actionHashes := make(map[string]int)    // for inner loop detection
	actionTypeCount := make(map[string]int) // for progress stagnation detection
	treePaths := make(map[string]int)       // track repeated scope/tree calls per path

	for iteration := 0; iteration < maxIter; iteration++ {
		select {
		case <-ctx.Done():
			loopResult.TerminalReason = "context_canceled"
			loopResult.Iterations = iteration
			loopResult.Actions = allActions
			loopResult.CompletedAt = time.Now()
			return loopResult, ctx.Err()
		default:
		}

		// Handle token limits
		trimmedMessages := w.handleTokenLimits(messages)

		// Cap max tokens: text mode produces a single compact JSON action,
		// full mode may produce tool calls with reasoning — 4096 is plenty.
		maxTokens := 4096
		if config.TextMode {
			maxTokens = 2048
		}
		req := &provider.ChatCompletionRequest{
			Model:          w.provider.Config.Model,
			Messages:       trimmedMessages,
			Temperature:    0.1,
			MaxTokens:      maxTokens,
			ResponseFormat: w.responseFormat(),
		}

		log.Printf("[ActionLoop] Iteration %d/%d for task %s (messages: %d, textMode: %v)", iteration+1, maxIter, task.ID, len(trimmedMessages), config.TextMode)

		resp, usedMsgs, err := w.callWithContextRetry(ctx, req)
		if err != nil {
			loopResult.TerminalReason = "error"
			loopResult.Iterations = iteration + 1
			loopResult.Actions = allActions
			loopResult.Success = false
			loopResult.Error = err.Error()
			loopResult.CompletedAt = time.Now()
			return loopResult, fmt.Errorf("LLM call failed on iteration %d: %w", iteration+1, err)
		}
		// If messages were truncated by retry, update the working set
		if len(usedMsgs) < len(trimmedMessages) {
			messages = usedMsgs
		}

		if len(resp.Choices) == 0 {
			loopResult.TerminalReason = "error"
			loopResult.Iterations = iteration + 1
			loopResult.Actions = allActions
			loopResult.Success = false
			loopResult.Error = "no response from provider"
			loopResult.CompletedAt = time.Now()
			return loopResult, fmt.Errorf("no response from provider on iteration %d", iteration+1)
		}

		llmResponse := resp.Choices[0].Message.Content
		loopResult.Response = llmResponse
		loopResult.TokensUsed += resp.Usage.TotalTokens

		// Add assistant message to conversation
		messages = append(messages, provider.ChatMessage{Role: "assistant", Content: llmResponse})
		if conversationCtx != nil {
			conversationCtx.AddMessage("assistant", llmResponse, resp.Usage.CompletionTokens)
		}

		// Parse actions — text mode uses simple JSON parser (10 actions),
		// legacy mode uses full JSON decoder (60+ actions)
		var env *actions.ActionEnvelope
		var parseErr error
		if config.TextMode {
			env, parseErr = actions.ParseSimpleJSON([]byte(llmResponse))
		} else {
			env, parseErr = actions.DecodeLenient([]byte(llmResponse))
		}
		if parseErr != nil {
			var validationErr *actions.ValidationError
			if errors.As(parseErr, &validationErr) {
				// JSON parsed fine but action fields are incomplete.
				// Give specific feedback and let the model retry — don't count
				// this as a hard parse failure.
				consecutiveValidationFailures++
				if consecutiveValidationFailures >= 8 {
					loopResult.TerminalReason = "validation_failures"
					loopResult.Iterations = iteration + 1
					loopResult.Actions = allActions
					loopResult.Success = false
					loopResult.Error = fmt.Sprintf("repeated validation failures: %v", validationErr)
					loopResult.CompletedAt = time.Now()
					return loopResult, nil
				}
				// Give increasingly specific examples as the model keeps failing
				feedback := fmt.Sprintf("## Action Validation Error (attempt %d/8)\n\nYour JSON was valid but incomplete: %v\n\nYou MUST respond with exactly ONE of these JSON formats:\n"+
					"  {\"action\": \"scope\", \"path\": \".\"}\n"+
					"  {\"action\": \"read\", \"path\": \"file.go\"}\n"+
					"  {\"action\": \"search\", \"query\": \"pattern\"}\n"+
					"  {\"action\": \"edit\", \"path\": \"file.go\", \"old\": \"text\", \"new\": \"replacement\"}\n"+
					"  {\"action\": \"write\", \"path\": \"file.go\", \"content\": \"full content\"}\n"+
					"  {\"action\": \"build\"}\n"+
					"  {\"action\": \"test\"}\n"+
					"  {\"action\": \"done\", \"reason\": \"summary\"}\n\n"+
					"Start with: {\"action\": \"scope\", \"path\": \".\"}", consecutiveValidationFailures, validationErr)
				messages = append(messages, provider.ChatMessage{Role: "user", Content: feedback})
				if conversationCtx != nil {
					conversationCtx.AddMessage("user", feedback, len(feedback)/4)
				}
				log.Printf("[ActionLoop] Validation error on iteration %d: %v", iteration+1, validationErr)
				continue
			}

			// Actual JSON parse failure — check if the model slipped into conversational mode
			isConversational := isConversationalResponse(llmResponse)
			if isConversational {
				// Don't count conversational slip-ups the same as JSON typos —
				// nudge the agent back into autonomous mode
				feedback := "## AUTONOMOUS MODE REMINDER\n\n" +
					"You are an AUTONOMOUS agent, not a chatbot. Do NOT ask questions or wait for instructions. " +
					"You must decide what to do next on your own and respond with a JSON action.\n\n" +
					"Analyze the task and previous results, then take the next logical action. " +
					"If you've completed the work, use {\"action\": \"done\", \"reason\": \"summary\"}. " +
					"If you need more information, use search or read actions. " +
					"RESPOND WITH JSON ONLY."
				messages = append(messages, provider.ChatMessage{Role: "user", Content: feedback})
				if conversationCtx != nil {
					conversationCtx.AddMessage("user", feedback, len(feedback)/4)
				}
				log.Printf("[ActionLoop] Conversational slip on iteration %d, nudging back to autonomous mode", iteration+1)
				continue
			}

			consecutiveParseFailures++
			if consecutiveParseFailures >= 5 {
				loopResult.TerminalReason = "parse_failures"
				loopResult.Iterations = iteration + 1
				loopResult.Actions = allActions
				loopResult.Success = false
				loopResult.Error = fmt.Sprintf("five consecutive parse failures: %v", parseErr)
				loopResult.CompletedAt = time.Now()
				return loopResult, nil
			}

			feedback := fmt.Sprintf("## Parse Error (attempt %d/5)\n\nFailed to parse your response as valid JSON: %v\n\nYou MUST respond with a SINGLE JSON object in this exact format:\n{\"action\": \"scope\", \"path\": \".\"}\n\nValid actions: scope, read, search, edit, write, build, test, bash, git_commit, git_push, done\n\nDo NOT wrap in an array. Do NOT include any text outside the JSON object.", consecutiveParseFailures, parseErr)
			messages = append(messages, provider.ChatMessage{Role: "user", Content: feedback})
			if conversationCtx != nil {
				conversationCtx.AddMessage("user", feedback, len(feedback)/4)
			}
			log.Printf("[ActionLoop] Parse error on iteration %d: %v", iteration+1, parseErr)
			continue
		}
		consecutiveParseFailures = 0
		consecutiveValidationFailures = 0

		// Check for empty actions (agent just provided analysis)
		if len(env.Actions) == 0 {
			loopResult.TerminalReason = "no_actions"
			loopResult.Iterations = iteration + 1
			loopResult.Actions = allActions
			loopResult.CompletedAt = time.Now()
			return loopResult, nil
		}

		// Execute actions
		results, execErr := config.Router.Execute(ctx, env, config.ActionContext)
		if execErr != nil {
			loopResult.TerminalReason = "error"
			loopResult.Iterations = iteration + 1
			loopResult.Actions = allActions
			loopResult.Success = false
			loopResult.Error = execErr.Error()
			loopResult.CompletedAt = time.Now()
			return loopResult, nil
		}

		allActions = append(allActions, results...)
		tracker.Update(iteration+1, results)

		// Auto-checkpoint: if the agent wrote or edited files successfully,
		// automatically create a WIP checkpoint commit so work is preserved
		// even if the agent times out or crashes before emitting git_commit.
		if config.Router != nil {
			needsCheckpoint := false
			for i, act := range env.Actions {
				if i < len(results) && results[i].Status == "executed" {
					switch act.Type {
					case actions.ActionWriteFile, actions.ActionEditCode, actions.ActionApplyPatch:
						needsCheckpoint = true
					}
				}
			}
			if needsCheckpoint {
				cpMsg := fmt.Sprintf("[WIP] Auto-checkpoint after file changes\n\nBead: %s\nAgent: %s",
					task.BeadID, w.agent.ID)
				if cAgent := config.Router.GetContainerAgent(task.ProjectID); cAgent != nil {
					cpResult, cpErr := cAgent.GitCommit(ctx, cpMsg, nil)
					if cpErr == nil {
						log.Printf("[ActionLoop] Auto-checkpoint (container) for bead %s: %v", task.BeadID, cpResult.CommitSHA)
					}
				} else if config.Router.Git != nil {
					cpResult, cpErr := config.Router.Git.Commit(ctx, task.BeadID, w.agent.ID, cpMsg, nil, true)
					if cpErr == nil {
						log.Printf("[ActionLoop] Auto-checkpoint commit created for bead %s: %v", task.BeadID, cpResult)
					}
				}
			}
		}

		// Track action types for progress stagnation detection
		for _, act := range env.Actions {
			actionTypeCount[act.Type]++
			if act.Type == actions.ActionReadTree {
				p := act.Path
				if p == "" {
					p = "."
				}
				treePaths[p]++
			}
		}

		// Log the iteration
		loopResult.ActionLog = append(loopResult.ActionLog, ActionLogEntry{
			Iteration: iteration + 1,
			Actions:   env.Actions,
			Results:   results,
			Timestamp: time.Now(),
		})

		// Notify caller that progress was made so heartbeat timestamps can be updated.
		if config.OnProgress != nil {
			config.OnProgress()
		}

		// Check for terminal actions
		termReason := checkTerminalCondition(env, results)
		if termReason != "" {
			// Auto-push on completion: if the agent is done, push any pending commits.
			if termReason == "completed" && config.Router != nil {
				if cAgent := config.Router.GetContainerAgent(task.ProjectID); cAgent != nil {
					pushResult, pushErr := cAgent.GitPush(ctx, "", false)
					if pushErr != nil {
						log.Printf("[ActionLoop] Auto-push (container) failed for bead %s: %v", task.BeadID, pushErr)
					} else {
						log.Printf("[ActionLoop] Auto-push (container) succeeded for bead %s: %v", task.BeadID, pushResult.Output)
					}
				} else if config.Router.Git != nil {
					pushResult, pushErr := config.Router.Git.Push(ctx, task.BeadID, "", false)
					if pushErr != nil {
						log.Printf("[ActionLoop] Auto-push after completion failed for bead %s: %v", task.BeadID, pushErr)
					} else {
						log.Printf("[ActionLoop] Auto-push succeeded for bead %s: %v", task.BeadID, pushResult)
					}
				}
			}

			loopResult.TerminalReason = termReason
			loopResult.Iterations = iteration + 1
			loopResult.Actions = allActions
			loopResult.CompletedAt = time.Now()

			// Record lessons from build failures
			w.recordBuildLessons(config, env, results)

			break
		}

		// Record lessons from build failures even on non-terminal iterations
		w.recordBuildLessons(config, env, results)

		// Inner loop detection: hash the actions and check for repeats
		hash := hashActions(env.Actions)
		actionHashes[hash]++
		if actionHashes[hash] >= 10 {
			loopResult.TerminalReason = "inner_loop"
			loopResult.Iterations = iteration + 1
			loopResult.Actions = allActions
			loopResult.Success = false
			loopResult.Error = "detected stuck inner loop (same actions repeated 10 times)"
			loopResult.CompletedAt = time.Now()

			if config.LessonsProvider != nil {
				_ = config.LessonsProvider.RecordLesson(
					task.ProjectID, "loop_pattern",
					"Agent stuck in action loop",
					fmt.Sprintf("Agent repeated the same actions 10 times. Actions hash: %s", hash),
					task.BeadID, w.agent.ID,
				)
			}
			return loopResult, nil
		}
		if actionHashes[hash] >= 5 {
			log.Printf("[ActionLoop] Warning: same actions repeated %d times (hash %s)", actionHashes[hash], hash[:8])
		}

		// Progress stagnation detection: check if agent is looping without making meaningful progress
		if stagnant, reason := tracker.IsProgressStagnant(iteration+1, actionTypeCount); stagnant {
			loopResult.TerminalReason = "progress_stagnant"
			loopResult.Iterations = iteration + 1
			loopResult.Actions = allActions
			loopResult.Success = false
			loopResult.Error = fmt.Sprintf("agent making no meaningful progress: %s", reason)
			loopResult.CompletedAt = time.Now()

			log.Printf("[ActionLoop] Progress stagnant for task %s: %s", task.ID, reason)

			// Store progress metrics for remediation analysis
			if loopResult.Metadata == nil {
				loopResult.Metadata = make(map[string]interface{})
			}
			loopResult.Metadata["progress_metrics"] = tracker.GetProgressMetrics()
			loopResult.Metadata["stagnation_reason"] = reason
			loopResult.Metadata["action_type_counts"] = actionTypeCount

			return loopResult, nil
		}

		// Warn the agent if it is repeating scope on a path it already explored
		var treeWarning string
		for _, act := range env.Actions {
			if act.Type == actions.ActionReadTree {
				p := act.Path
				if p == "" {
					p = "."
				}
				if treePaths[p] > 1 {
					treeWarning = fmt.Sprintf("\n**WARNING: You already listed directory %q %d times. The contents have not changed. Move on to your next action (search, read, or edit).**\n", p, treePaths[p])
					break
				}
			}
		}

		// Format results as user message, prepended with progress summary
		feedback := tracker.Summary(iteration+1) + treeWarning + actions.FormatResultsAsUserMessage(results)
		messages = append(messages, provider.ChatMessage{Role: "user", Content: feedback})
		if conversationCtx != nil {
			conversationCtx.AddMessage("user", feedback, len(feedback)/4)
		}

		// Persist conversation context periodically
		if conversationCtx != nil && config.DB != nil && (iteration%3 == 2 || iteration == maxIter-1) {
			if err := config.DB.UpdateConversationContext(conversationCtx); err != nil {
				log.Printf("[ActionLoop] Warning: Failed to persist conversation: %v", err)
			}
		}
	}

	// If we exhausted iterations without terminal condition
	if loopResult.TerminalReason == "" {
		loopResult.TerminalReason = "max_iterations"
		loopResult.Iterations = maxIter
		loopResult.Actions = allActions
		loopResult.CompletedAt = time.Now()
	}

	// Extract lessons from the completed loop
	if config.DB != nil && task.ProjectID != "" {
		entries := flattenActionLog(loopResult.ActionLog)
		if len(entries) > 0 {
			extractor := memory.NewExtractor(config.DB, memory.NewHashEmbedder())
			extractor.ExtractFromLoop(task.ProjectID, task.BeadID, entries, loopResult.TerminalReason)
		}
	}

	// Final persist
	if conversationCtx != nil && config.DB != nil {
		if err := config.DB.UpdateConversationContext(conversationCtx); err != nil {
			log.Printf("[ActionLoop] Warning: Failed to persist final conversation: %v", err)
		}
	}

	return loopResult, nil
}

// buildEnhancedSystemPrompt builds the system prompt with ReAct operating model first,
// brief persona role second, and action format last.
func (w *Worker) buildEnhancedSystemPrompt(lp LessonsProvider, projectID, progressCtx string) string {
	// Get lessons — try file-based LESSONS.md first, then semantic search, then recency
	var lessons string
	if projectID != "" {
		lessonsFile := actions.NewLessonsFile(".")
		lessons = lessonsFile.GetLessonsForPrompt()
	}
	if lessons == "" && lp != nil && projectID != "" {
		// Use semantic retrieval if we have task context
		if progressCtx != "" {
			lessons = lp.GetRelevantLessons(projectID, progressCtx, 5)
		}
		if lessons == "" {
			lessons = lp.GetLessonsForPrompt(projectID)
		}
	}

	// 1. Action format with ReAct pattern FIRST — this is the operating model
	var prompt string
	if w.textMode {
		prompt = actions.BuildSimpleJSONPrompt(lessons, progressCtx) + "\n\n"
	} else {
		prompt = actions.BuildEnhancedPrompt(lessons, progressCtx) + "\n\n"
	}

	// 2. Brief persona role context — just enough for the model to know its specialization.
	// NOT the verbose analysis instructions that override the ReAct action bias.
	persona := w.agent.Persona
	if persona == nil {
		prompt += fmt.Sprintf("# Your Role\nYou are %s. Act on the task given to you.\n\n", w.agent.Name)
	} else {
		prompt += "# Your Role\n"
		if persona.Character != "" {
			prompt += persona.Character + "\n"
		} else {
			prompt += fmt.Sprintf("You are %s.\n", w.agent.Name)
		}
		if persona.Mission != "" {
			prompt += "Mission: " + persona.Mission + "\n"
		}
		prompt += "\n"
	}

	return prompt
}

// checkTerminalCondition checks if any action in the envelope signals termination.
// Terminal actions must have succeeded — a failed close_bead should not terminate.
func checkTerminalCondition(env *actions.ActionEnvelope, results []actions.Result) string {
	for i, a := range env.Actions {
		switch a.Type {
		case actions.ActionCloseBead:
			if i < len(results) && results[i].Status == "error" {
				continue // close failed, don't terminate
			}
			return "completed"
		case actions.ActionDone:
			return "completed"
		case actions.ActionEscalateCEO:
			return "escalated"
		}
	}
	return ""
}

// recordBuildLessons checks action results for build/test failures and records lessons.
func (w *Worker) recordBuildLessons(config *LoopConfig, env *actions.ActionEnvelope, results []actions.Result) {
	if config.LessonsProvider == nil {
		return
	}

	for i, r := range results {
		if r.Status != "error" && r.Status != "executed" {
			continue
		}

		var category, title, detail string

		switch r.ActionType {
		case actions.ActionBuildProject:
			if r.Status == "error" || (r.Metadata != nil && r.Metadata["success"] == false) {
				category = "compiler_error"
				title = "Build failure"
				output, _ := r.Metadata["output"].(string)
				if output == "" {
					output = r.Message
				}
				detail = truncateForLesson(output)
			}
		case actions.ActionRunTests:
			if r.Status == "error" || (r.Metadata != nil && r.Metadata["success"] == false) {
				category = "test_failure"
				title = "Test failure"
				output, _ := r.Metadata["output"].(string)
				if output == "" {
					output = r.Message
				}
				detail = truncateForLesson(output)
			}
		case actions.ActionApplyPatch, actions.ActionEditCode:
			if r.Status == "error" {
				category = "edit_failure"
				title = "Patch/edit failure"
				detail = truncateForLesson(r.Message)
			}
		}

		if category != "" {
			_ = i // suppress unused warning
			_ = config.LessonsProvider.RecordLesson(
				config.ActionContext.ProjectID,
				category, title, detail,
				config.ActionContext.BeadID,
				w.agent.ID,
			)
		}
	}
}

func truncateForLesson(s string) string {
	if len(s) <= 500 {
		return s
	}
	return s[:500]
}

// flattenActionLog converts worker ActionLogEntries into memory.ActionEntry
// for extraction analysis.
func flattenActionLog(log []ActionLogEntry) []memory.ActionEntry {
	var entries []memory.ActionEntry
	for _, entry := range log {
		for _, r := range entry.Results {
			path := ""
			if r.Metadata != nil {
				if p, ok := r.Metadata["path"].(string); ok {
					path = p
				}
			}
			entries = append(entries, memory.ActionEntry{
				Iteration:  entry.Iteration,
				ActionType: string(r.ActionType),
				Status:     r.Status,
				Message:    r.Message,
				Path:       path,
			})
		}
	}
	return entries
}

// hashActions computes a deterministic hash of action types and key fields.
func hashActions(acts []actions.Action) string {
	var sb strings.Builder
	for _, a := range acts {
		sb.WriteString(a.Type)
		sb.WriteString("|")
		sb.WriteString(a.Path)
		sb.WriteString("|")
		sb.WriteString(a.Command)
		sb.WriteString("|")
	}
	h := sha256.Sum256([]byte(sb.String()))
	return hex.EncodeToString(h[:8])
}
