#!/bin/bash
# Local provider bootstrap â€” copy to bootstrap.local and fill in your values.
# bootstrap.local is gitignored and will not be committed.
#
# Runs automatically after: make start, make restart
# Or manually via: make bootstrap, ./bootstrap.local
#
# Architecture: Loom -> TokenHub -> LLM Providers
# TokenHub handles routing, health tracking, failover, and scoring.
# Loom registers TokenHub as its single provider endpoint.

set -e

LOOM_URL="${LOOM_URL:-http://localhost:8080}"
TOKENHUB_URL="${TOKENHUB_URL:-http://localhost:8090}"
TOKENHUB_ADMIN_TOKEN="${TOKENHUB_ADMIN_TOKEN:-loom-tokenhub-admin}"
LOOMCTL="${LOOMCTL:-./loomctl}"

if [ ! -f "$LOOMCTL" ]; then
    echo "Building loomctl..."
    go build -o loomctl ./cmd/loomctl
fi

th_admin() {
    curl -sf -X POST "$TOKENHUB_URL/admin/v1/$1" \
        -H "Authorization: Bearer $TOKENHUB_ADMIN_TOKEN" \
        -H "Content-Type: application/json" \
        -d "$2"
}

# === Phase 1: Register your LLM providers with TokenHub ===

# Local vLLM example (configured via TOKENHUB_VLLM_ENDPOINTS env var in docker-compose):
# th_admin "models" '{"id":"my-model","provider_id":"vllm","weight":7,"max_context_tokens":32000,"enabled":true}'

# Cloud provider example:
# th_admin "providers" '{"id":"my-cloud","type":"openai","endpoint":"https://api.example.com","api_key":"sk-..."}'
# th_admin "models" '{"id":"cloud-model","provider_id":"my-cloud","weight":8,"max_context_tokens":128000,"enabled":true}'

# === Phase 2: Register TokenHub as Loom's single provider ===

# $LOOMCTL provider register "tokenhub" \
#     --name "TokenHub (LLM Router)" \
#     --type "openai" \
#     --endpoint "http://tokenhub:8080/v1" \
#     --model "my-model" \
#     --server "$LOOM_URL"
