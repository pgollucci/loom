services:
  # PostgreSQL database for Temporal
  temporal-postgresql:
    image: postgres:15-alpine
    container_name: temporal-postgresql
    restart: unless-stopped
    environment:
      POSTGRES_USER: temporal
      POSTGRES_PASSWORD: temporal
      POSTGRES_DB: temporal
    networks:
      - loom-network
    volumes:
      - temporal-db-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U temporal"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Temporal server with auto-setup
  temporal:
    image: temporalio/auto-setup:1.22.4
    container_name: temporal
    restart: unless-stopped
    depends_on:
      temporal-postgresql:
        condition: service_healthy
    environment:
      - DB=postgresql
      - DB_PORT=5432
      - POSTGRES_USER=temporal
      - POSTGRES_PWD=temporal
      - POSTGRES_SEEDS=temporal-postgresql
      - DYNAMIC_CONFIG_FILE_PATH=config/dynamicconfig/development-sql.yaml
      - ENABLE_ES=false
      - ES_SEEDS=
      - ES_VERSION=
    ports:
      - "7233:7233"  # gRPC port
    networks:
      - loom-network
    volumes:
      - ./config/temporal:/etc/temporal/config/dynamicconfig
    healthcheck:
      test: ["CMD", "tctl", "--address", "temporal:7233", "cluster", "health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Temporal Web UI
  temporal-ui:
    image: temporalio/ui:2.21.3
    container_name: temporal-ui
    restart: unless-stopped
    depends_on:
      temporal:
        condition: service_healthy
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CORS_ORIGINS=http://localhost:3000
    ports:
      - "8088:8080"  # Temporal UI on different port to avoid conflict with loom
    networks:
      - loom-network

  loom:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        GITHUB_TOKEN: ${GITHUB_TOKEN}
    image: loom:latest
    container_name: loom
    restart: unless-stopped
    depends_on:
      temporal:
        condition: service_healthy
    ports:
      - "8080:8081"
      - "3307:3307"     # Dolt SQL server for beads federation
    environment:
      - LOOM_PASSWORD=${LOOM_PASSWORD}
      - TZ=UTC
      - TEMPORAL_HOST=temporal:7233
      - TEMPORAL_NAMESPACE=default
      - CONFIG_PATH=/app/config.yaml
      - DOLT_PORT=3307
    networks:
      - loom-network
    extra_hosts:
      - "plubbit.local:10.11.101.250"
      - "sparky.local:10.11.100.116"
    volumes:
      # Persist SQLite database and project clones across container restarts
      - loom-db:/app/data
      # Mount known_hosts for git SSH operations (read-only)
      # Loom uses its own per-project SSH deploy keys (stored encrypted in DB)
      - ~/.ssh/known_hosts:/home/loom/.ssh/known_hosts:ro
    healthcheck:
      test: ["CMD", "/app/loom", "-version"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  loom-test:
    build:
      context: .
      dockerfile: Dockerfile
      target: builder
      args:
        GITHUB_TOKEN: ${GITHUB_TOKEN}
    container_name: loom-test
    depends_on:
      temporal:
        condition: service_healthy
    environment:
      - TEMPORAL_HOST=temporal:7233
      - TEMPORAL_REQUIRED=true
    networks:
      - loom-network
    command: ["go", "test", "-v", "./..."]

  # OpenTelemetry Collector
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    container_name: otel-collector
    restart: unless-stopped
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./config/otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "4317:4317"   # OTLP gRPC receiver
      - "4318:4318"   # OTLP HTTP receiver
      - "8888:8888"   # Prometheus metrics exposed by the collector
      - "8889:8889"   # Prometheus exporter
    networks:
      - loom-network

  # Prometheus for metrics storage
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - loom-network

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - ./config/grafana/datasources:/etc/grafana/provisioning/datasources
      - ./config/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - grafana-data:/var/lib/grafana
    ports:
      - "3000:3000"
    networks:
      - loom-network
    depends_on:
      - prometheus

  # Jaeger for distributed tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    restart: unless-stopped
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    ports:
      - "16686:16686"  # Jaeger UI
      - "14268:14268"  # Jaeger collector HTTP
    networks:
      - loom-network

networks:
  loom-network:
    driver: bridge

volumes:
  temporal-db-data:
  loom-db:
  prometheus-data:
  grafana-data:
