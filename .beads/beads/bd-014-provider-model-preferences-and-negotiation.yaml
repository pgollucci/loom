id: bd-014
type: epic
title: P1 - Provider model preference list + negotiation + dynamic scoring
description: |
  Add a system-level “recommended models” preference list that Arbiter uses to
  help providers pick the best available model (provider-side negotiation).

  Goal
  - Each provider implementation should select (“negotiate for”) the best model
    it can serve, guided by Arbiter’s recommended model list and a dynamic score
    computed from observed availability/latency/throughput (and later cost).

  Requirements
  1) Recommended model list (Arbiter-owned)
     - Arbiter maintains an ordered list of recommended models with per-model
       metadata used for scoring and selection.
     - The model list must support multiple factors per model, including:
       - Estimated total parameter size (e.g., 480B vs 30B)
       - “Active” parameter size when encoded in the name (e.g., A35B)
       - Interactivity class (fast/medium/slow response expectation)
       - Best parallelization hints (e.g., tensor-parallel degree, kv-cache)
       - Suggested minimum GPU memory / GPU class (heuristic)
     - The model list must include (at minimum):
       - NVIDIA-Nemotron-3-Nano-30B-A3B-BF16 (already used in bootstrap)
       - Qwen2.5-Coder variants already registered in the system
       - Qwen/Qwen3-Coder-480B-A35B-Instruct
       - Qwen/Qwen3-Coder-30B-A3B-Instruct

  2) Provider negotiation
     - Providers should not be pinned to a single fixed model string.
     - On provider registration/update, and periodically (or on demand), a
       provider implementation should:
       - call provider’s model listing endpoint (OpenAI-compatible /models)
       - intersect discovered models with Arbiter’s recommended list
       - pick the best eligible model by Arbiter-computed score
       - record the selected model in provider state (and expose via API/UI)
     - If a provider cannot serve any recommended model:
       - fall back to its configured model (if present)
       - otherwise pick the best available discovered model by heuristic
       - record rationale in provider context

  3) Dynamic model scoring
     - Arbiter computes a model score per provider-model candidate based on:
       - availability/health (up/down, error rates)
       - observed latency (TTFB and full completion time)
       - throughput (tokens/sec when measurable)
       - concurrency/queue depth (if measurable)
       - future: dollar cost (when available)
     - Arbiter should persist rolling metrics and a current score.

  4) Model name decoding / GPU implications
     - Arbiter should parse model names to extract useful signals, at minimum:
       - Total parameter count (“480B” > “38B” > “30B”)
       - “Active parameter” count when present (“A35B”, “A3B”)
       - Precision/format hints when present (BF16/FP16/etc)
       - Instruction-tuned vs base (“Instruct”)
     - Arbiter should expose derived fields in model metadata so selection and
       UI can explain why a model is chosen.
     - If a provider exposes GPU selection (via its own OpenAPI extensions or
       vendor-specific endpoints):
       - include GPU capability constraints in negotiation (VRAM / GPU type)
       - allow provider-side selection to pick an appropriate GPU for the model
       - record chosen GPU (if any) alongside chosen model.

  Suggested Implementation
  - Add a ModelCatalog / RecommendedModels component:
    - data model persisted in config DB (and exported/imported via config API)
    - supports model metadata + derived parsed fields
  - Add observed metrics and score tracking:
    - per-provider/per-model rolling windows
    - activity instrumentation around chat completion calls
  - Extend provider schema/API:
    - configured_model (requested)
    - selected_model (effective)
    - model_score + metrics snapshot
    - optional selected_gpu / gpu_constraints

  Acceptance Criteria
  - Arbiter has a recommended model list with metadata and parsing.
  - Providers can auto-select a best model from the recommended list.
  - Arbiter computes and persists model scores based on real runtime signals.
  - Provider state exposes configured vs selected model (and optional GPU).
  - The model list includes the Qwen3 Coder 480B and 30B instruct models.

status: closed
priority: 1
project_id: arbiter
assigned_to: null
blocked_by: []
blocks: []
parent: null
children:
  - bd-015
  - bd-016
  - bd-017
  - bd-018
  - bd-019
  - bd-020
tags:
  - p1
  - providers
  - models
  - negotiation
  - scoring
  - gpu
created_at: 2026-01-19T08:20:00Z
updated_at: 2026-01-19T18:30:00Z
closed_at: 2026-01-19T18:30:00Z
context:
  source: user-request
